# Welcome to ParallelIQ ğŸ‘‹

### ğŸš€ Automating AI Infrastructure with Predictive Orchestration & Compiler Intelligence

<p align="center">
  <a href="https://paralleliq.ai"><img src="https://img.shields.io/badge/Website-paralleliq.ai-blue?style=for-the-badge&logo=google-chrome&logoColor=white" /></a>
  <a href="https://www.linkedin.com/company/paralleliq"><img src="https://img.shields.io/badge/LinkedIn-ParallelIQ-0A66C2?style=for-the-badge&logo=linkedin&logoColor=white" /></a>
  <a href="https://x.com/paralleliq"><img src="https://img.shields.io/badge/X-@paralleliq-000000?style=for-the-badge&logo=x&logoColor=white" /></a>
  <a href="https://www.crunchbase.com/organization/paralleliq"><img src="https://img.shields.io/badge/Crunchbase-ParallelIQ-0288D1?style=for-the-badge&logo=crunchbase&logoColor=white" /></a>
  <a href="https://www.medium.com/@samhoss93"><img src="https://img.shields.io/badge/Medium-Blog-000000?style=for-the-badge&logo=medium&logoColor=white" /></a>
</p>

---

## ğŸ§  Who We Are

**ParallelIQ** is an AI infrastructure company headquartered in **San Jose, California**, building the next generation of tools and standards for deploying, operating, and optimizing AI/LLM workloads at scale.

We believe the future of AI is not just about smarter models â€” it's about **smarter infrastructure**.

- ğŸ—ï¸ **Building open standards** for AI model deployment and operations
- ğŸ” **Developing runtime introspection tools** for Kubernetes-native AI inference
- ğŸ“š **Publishing community-driven knowledge** on production GenAI infrastructure
- âš¡ **Focused on GPU efficiency**, KV cache optimization, and LLM serving performance
- ğŸ›¡ï¸ **Championing governance and observability** for responsible AI operations
- ğŸ¤ **Open to collaborations** in MLOps, AI Infrastructure, and LLM tooling

![Profile Views](https://komarev.com/ghpvc/?username=paralleliq&color=blueviolet&label=Profile+Views&style=flat-square)
---

## ğŸ—‚ï¸ Open Source Projects

### ğŸ” [piqc](https://github.com/paralleliq/piqc) â€” PIQC Fact Collector
> *Kubernetes scanner that discovers LLMs running on vLLM and extracts their deployment and runtime facts.*

A Kubernetes-native introspection CLI that automatically discovers **vLLM inference deployments**, collects GPU metrics, runtime telemetry, and generates standardized **ModelSpec** documentation. Built for ML Eng, MLOps, and SRE teams.

`Python` Â· `Kubernetes` Â· `vLLM` Â· `GPU Metrics` Â· `ModelSpec`

---

### ğŸ“„ [modelspec](https://github.com/paralleliq/modelspec) â€” Open Declarative AI Model Specification
> *An open, declarative specification for describing how AI models are deployed, served, and operated in production.*

ModelSpec captures **execution, serving, and orchestration intent** â€” making implicit assumptions explicit in a machine-readable, human-auditable format. Runtime-agnostic. Cloud-agnostic. Built for real-world teams.

`JSON Schema` Â· `LLM Deployment` Â· `AI Infrastructure` Â· `MLOps` Â· `Observability`

---

### ğŸ“š [piqc-knowledge-base](https://github.com/paralleliq/piqc-knowledge-base) â€” Production Readiness Standards for GenAI
> *Production-ready checklists and frameworks for deploying LLMs, GenAI models, and AI infrastructure.*

A neutral, community-driven collection of **deployment checklists**, **infrastructure best practices**, **runtime diagnostics**, and **governance frameworks**. Covers vLLM, Kubernetes, GPU optimization, observability, compliance, and Day-0 to Day-2 operations.

`AI Infrastructure` Â· `vLLM` Â· `Kubernetes` Â· `GPU Optimization` Â· `AI Governance`

---

## ğŸ› ï¸ Tech Stack & Focus Areas

<p align="center">  
  <a href="https://www.python.org/"><img alt="Python" src="https://raw.githubusercontent.com/devicons/devicon/master/icons/python/python-original-wordmark.svg" width="55" height="55"/></a>  
  <a href="https://kubernetes.io/"><img alt="Kubernetes" src="https://raw.githubusercontent.com/devicons/devicon/master/icons/kubernetes/kubernetes-plain.svg" width="55" height="55"/></a>  
  <a href="https://www.docker.com/"><img alt="Docker" src="https://raw.githubusercontent.com/devicons/devicon/master/icons/docker/docker-original-wordmark.svg" width="55" height="55"/></a>  
  <a href="https://www.linux.org/"><img alt="Linux" src="https://raw.githubusercontent.com/devicons/devicon/master/icons/linux/linux-original.svg" width="55" height="55"/></a>  
  <a href="https://git-scm.com/"><img alt="Bash" src="https://raw.githubusercontent.com/devicons/devicon/master/icons/bash/bash-original.svg" width="55" height="55"/></a>  
  <a href="https://pytorch.org/"><img alt="PyTorch" src="https://raw.githubusercontent.com/devicons/devicon/master/icons/pytorch/pytorch-original.svg" width="55" height="55"/></a>  
</p>

---

## GitHub Analytics  
<p align="center">  
  <img height="180em" src="https://github-profile-summary-cards.vercel.app/api/cards/profile-details?username=paralleliq&theme=vue"/>  
  <img height="180em" src="https://github-readme-streak-stats.herokuapp.com/?user=paralleliq&show_icons=true&locale=en&layout=demo&theme=algolia"/>  
</p>  

## Activity Graph  
[![Samâ€™s GitHub activity graph](https://github-readme-activity-graph.vercel.app/graph?username=paralleliq&theme=react-dark)](https://github.com/ashutosh00710/github-readme-activity-graph)

---

## ğŸ“¬ Let's Connect

ğŸ“¨ **Business Inquiries:** [sam@paralleliq.ai](mailto:sam@paralleliq.ai)  
ğŸ‘¤ **Founder & CEO:** Sam Hosseini  
ğŸŒ **Website:** [paralleliq.ai](https://paralleliq.ai)

---

[![Typing SVG](https://readme-typing-svg.herokuapp.com?font=Fira+Code&color=%237B2FBE&size=22&duration=2500&center=true&vCenter=true&lines=Building+the+future+of+AI+Infrastructure;Open+Standards+for+LLM+Deployment;Model-Aware+GPU+Control+Plane;Glad+to+see+you+here!+â­)](https://git.io/typing-svg)

---

> *Making AI deployment knowledge open, neutral, and accessible to everyone.*  
> **ParallelIQ**
